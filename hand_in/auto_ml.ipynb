{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.storages import RDBStorage\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from src.dataset import get_datasets\n",
    "from src.feature import create_features, split\n",
    "from src.prediction import init_prophet_model\n",
    "from src.benchmark import extend_by_predictions_and_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "    \"Price\",\n",
    "    \"Hydro\",\n",
    "    \"Pumped storage generation\",\n",
    "    \"Solar\",\n",
    "    \"Wind offshore\",\n",
    "    \"Wind onshore\",\n",
    "    \"temperature_2m\",\n",
    "    \"precipitation\",\n",
    "    \"wind_speed_100m\",\n",
    "    \"direct_radiation\",\n",
    "]\n",
    "WINDOW_SIZE = 24\n",
    "\n",
    "CANDIDATE_FEATURES = [\n",
    "    'Hydro',\n",
    "    'Pumped storage generation', 'Solar',\n",
    "    'Wind offshore', 'Wind onshore', 'temperature_2m', 'precipitation',\n",
    "    'wind_speed_100m', 'direct_radiation', 'hour', 'dayofweek', 'dayofyear'\n",
    "]\n",
    "\n",
    "for i in range(1, 15):\n",
    "    CANDIDATE_FEATURES.append(f'ma_{i}_days')\n",
    "    CANDIDATE_FEATURES.append(f'ma_{i}_days_pumped_storage_generation')\n",
    "\n",
    "# Remove duplicates (if any) while preserving order.\n",
    "CANDIDATE_FEATURES = list(dict.fromkeys(CANDIDATE_FEATURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22c6e13d97243f08238eebd8689c2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c8b353917a47f6b38a5c8bcebe6e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optuna Trials:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 21:50:31,987] Trial 8 finished with value: 137.34579957043564 and parameters: {'base_score': 0.07550256199518257, 'learning_rate': 0.0021228831950554083, 'max_depth': 40, 'n_estimators': 335, 'gamma': 0.2623531092500475, 'min_child_weight': 3, 'subsample': 0.5393459596520509, 'colsample_bylevel': 0.5346442829742823, 'max_delta_step': 1, 'early_stopping_rounds': 123}. Best is trial 8 with value: 137.34579957043564.\n",
      "[I 2025-02-16 21:50:34,580] Trial 3 finished with value: 135.36025937339815 and parameters: {'base_score': 0.48021377908335106, 'learning_rate': 0.0019409126308456031, 'max_depth': 50, 'n_estimators': 303, 'gamma': 1.9203122727100959, 'min_child_weight': 2, 'subsample': 0.994482939142921, 'colsample_bylevel': 0.5143726328994345, 'max_delta_step': 4, 'early_stopping_rounds': 62}. Best is trial 3 with value: 135.36025937339815.\n",
      "[I 2025-02-16 21:51:05,223] Trial 10 finished with value: 135.85561569461046 and parameters: {'base_score': 0.19288989535520484, 'learning_rate': 0.0015655133888922063, 'max_depth': 10, 'n_estimators': 272, 'gamma': 2.328522084246665, 'min_child_weight': 10, 'subsample': 0.6045550787799026, 'colsample_bylevel': 0.5542312789400233, 'max_delta_step': 5, 'early_stopping_rounds': 68}. Best is trial 3 with value: 135.36025937339815.\n",
      "[I 2025-02-16 21:52:01,958] Trial 1 finished with value: 131.26908980600152 and parameters: {'base_score': 0.30283384438721783, 'learning_rate': 0.003017027246829512, 'max_depth': 27, 'n_estimators': 746, 'gamma': 0.7600974859006115, 'min_child_weight': 5, 'subsample': 0.9983379489352187, 'colsample_bylevel': 0.9936798249973429, 'max_delta_step': 3, 'early_stopping_rounds': 171}. Best is trial 1 with value: 131.26908980600152.\n",
      "[I 2025-02-16 21:53:04,763] Trial 2 finished with value: 37.172935543075845 and parameters: {'base_score': 0.17683135912244008, 'learning_rate': 0.3247461393932021, 'max_depth': 24, 'n_estimators': 228, 'gamma': 1.4716491771144775, 'min_child_weight': 6, 'subsample': 0.825449988810531, 'colsample_bylevel': 0.5371617580511171, 'max_delta_step': 0, 'early_stopping_rounds': 49}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:53:05,739] Trial 12 finished with value: 135.3507392962035 and parameters: {'base_score': 0.5901231722811655, 'learning_rate': 0.0017338680509034403, 'max_depth': 18, 'n_estimators': 433, 'gamma': 3.5744748654248015, 'min_child_weight': 1, 'subsample': 0.8267385198292667, 'colsample_bylevel': 0.7058654167685924, 'max_delta_step': 3, 'early_stopping_rounds': 182}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:53:44,700] Trial 11 finished with value: 121.01258216883299 and parameters: {'base_score': 0.25503498173933736, 'learning_rate': 0.0033394889066485686, 'max_depth': 63, 'n_estimators': 580, 'gamma': 1.1072852474778365, 'min_child_weight': 3, 'subsample': 0.6570054017111628, 'colsample_bylevel': 0.5660472526790027, 'max_delta_step': 9, 'early_stopping_rounds': 230}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:53:51,858] Trial 14 finished with value: 135.253294664145 and parameters: {'base_score': 0.8210115164438251, 'learning_rate': 0.0010401284922074573, 'max_depth': 21, 'n_estimators': 204, 'gamma': 1.6424114320158711, 'min_child_weight': 1, 'subsample': 0.6683842406866478, 'colsample_bylevel': 0.6266329851734018, 'max_delta_step': 10, 'early_stopping_rounds': 162}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:54:02,184] Trial 15 finished with value: 135.8734011867692 and parameters: {'base_score': 0.4869710183526713, 'learning_rate': 0.0018185013813774298, 'max_depth': 20, 'n_estimators': 111, 'gamma': 0.8781696860632565, 'min_child_weight': 5, 'subsample': 0.6905565212795617, 'colsample_bylevel': 0.5652318783745716, 'max_delta_step': 9, 'early_stopping_rounds': 66}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:54:26,419] Trial 17 finished with value: 135.86091072794213 and parameters: {'base_score': 0.40780189970198144, 'learning_rate': 0.003976514243220421, 'max_depth': 75, 'n_estimators': 160, 'gamma': 2.8800768631257583, 'min_child_weight': 4, 'subsample': 0.8548969161704154, 'colsample_bylevel': 0.8808034037155131, 'max_delta_step': 3, 'early_stopping_rounds': 163}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:55:18,449] Trial 16 finished with value: 130.0949573686673 and parameters: {'base_score': 0.3618982709875125, 'learning_rate': 0.0015750077151947036, 'max_depth': 32, 'n_estimators': 502, 'gamma': 0.9312968044053671, 'min_child_weight': 4, 'subsample': 0.6407273277524103, 'colsample_bylevel': 0.5872923389509223, 'max_delta_step': 10, 'early_stopping_rounds': 86}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:55:35,467] Trial 4 finished with value: 48.0828536197098 and parameters: {'base_score': 0.17387442838294798, 'learning_rate': 0.213489087788219, 'max_depth': 55, 'n_estimators': 63, 'gamma': 0.5565157922724762, 'min_child_weight': 1, 'subsample': 0.7483098693305905, 'colsample_bylevel': 0.8669871446707498, 'max_delta_step': 8, 'early_stopping_rounds': 21}. Best is trial 2 with value: 37.172935543075845.\n",
      "[I 2025-02-16 21:57:41,780] Trial 20 finished with value: 34.97286226384726 and parameters: {'base_score': 0.004928628138485186, 'learning_rate': 0.44811376865349245, 'max_depth': 92, 'n_estimators': 54, 'gamma': 4.98468218803413, 'min_child_weight': 8, 'subsample': 0.8005895736464085, 'colsample_bylevel': 0.8145972390068144, 'max_delta_step': 7, 'early_stopping_rounds': 20}. Best is trial 20 with value: 34.97286226384726.\n",
      "[I 2025-02-16 21:57:48,779] Trial 18 finished with value: 37.54195930388616 and parameters: {'base_score': 0.05814426042621168, 'learning_rate': 0.30737350641967043, 'max_depth': 95, 'n_estimators': 669, 'gamma': 4.612680994066574, 'min_child_weight': 8, 'subsample': 0.8131299578047573, 'colsample_bylevel': 0.7681952258725113, 'max_delta_step': 0, 'early_stopping_rounds': 36}. Best is trial 20 with value: 34.97286226384726.\n"
     ]
    }
   ],
   "source": [
    "BEST_FEATURES = [\n",
    "    \"Pumped storage generation\",\n",
    "    \"Solar\",\n",
    "    \"Wind offshore\",\n",
    "    \"temperature_2m\",\n",
    "    \"wind_speed_100m\",\n",
    "    \"hour\",\n",
    "    \"dayofweek\",\n",
    "    \"dayofyear\",\n",
    "    \"ma_1_days\",\n",
    "    \"ma_1_days_pumped_storage_generation\",\n",
    "    \"ma_2_days\",\n",
    "    \"ma_2_days_pumped_storage_generation\",\n",
    "    \"ma_3_days\",\n",
    "    \"ma_4_days_pumped_storage_generation\",\n",
    "    \"ma_5_days_pumped_storage_generation\",\n",
    "    \"ma_6_days\",\n",
    "    \"ma_7_days\",\n",
    "    \"ma_8_days_pumped_storage_generation\",\n",
    "    \"ma_9_days_pumped_storage_generation\",\n",
    "    \"ma_10_days\",\n",
    "    \"ma_11_days\",\n",
    "    \"ma_12_days_pumped_storage_generation\",\n",
    "    \"ma_13_days\",\n",
    "    \"ma_14_days_pumped_storage_generation\",\n",
    "]\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.stdout = open(\"output.log\", \"w\")  # Redirects print output to a file\n",
    "sys.stderr = sys.stdout  # Redirect errors as well\n",
    "\n",
    "\n",
    "print(\"All outputs will be saved to output.log\")\n",
    "\n",
    "# =============================================================================\n",
    "# Precompute the Train/Test and Forecast Windows Outside the Objective\n",
    "# =============================================================================\n",
    "windowed_sets = []\n",
    "\n",
    "# Get and split datasets\n",
    "merged_df, _ = get_datasets()\n",
    "train, eval, test, benchmark, _, _, _ = split(merged_df)\n",
    "\n",
    "# Combine all available training data\n",
    "training_set = pd.concat([train, eval, test])[COLUMNS]\n",
    "benchmarking_set = benchmark[COLUMNS]\n",
    "\n",
    "# Iterate through forecast windows for rolling prediction\n",
    "for window_start in tqdm(range(WINDOW_SIZE, len(benchmarking_set) - WINDOW_SIZE, WINDOW_SIZE), desc=\"Preparing windowed datasets\"):\n",
    "    y_actual = benchmarking_set.iloc[window_start : window_start + WINDOW_SIZE][\"Price\"]\n",
    "    dataset_extended = pd.concat((training_set, benchmarking_set.iloc[:window_start]))\n",
    "    next_day = dataset_extended.index[-1] + pd.DateOffset(hours=1)\n",
    "\n",
    "    if next_day != y_actual.index[0]:\n",
    "        print(f\"\\nSkipping prediction for {next_day} due to missing entries.\\n\")\n",
    "        continue\n",
    "\n",
    "    dataset_extended_ps = extend_by_predictions_and_samples(dataset_extended, dataset_extended.index[-1])\n",
    "    dataset_extended_features = create_features(dataset_extended_ps)\n",
    "\n",
    "   # Split for training (all but last 24 hours) and prediction (the next 24 hours)\n",
    "    VALIDATION_SET_SIZE = 24 * 14\n",
    "    X_train_df = dataset_extended_features.iloc[:-WINDOW_SIZE - VALIDATION_SET_SIZE]\n",
    "    X_eval_df = dataset_extended_features.iloc[-WINDOW_SIZE - VALIDATION_SET_SIZE : -WINDOW_SIZE]\n",
    "    X_predict_df = dataset_extended_features.reindex(y_actual.index)\n",
    "    windowed_sets.append((X_train_df, X_predict_df, X_eval_df, y_actual))\n",
    "\n",
    "DB_URL = \"postgresql://optuna_user:postgres@localhost/optuna_db\"\n",
    "NUM_WORKERS = 30\n",
    "N_TRIALS_TOTAL = 500\n",
    "\n",
    "def objective(trial, worker_name, progress):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    # SELECTED_FEATURES = [\n",
    "    #     feature for feature in CANDIDATE_FEATURES if trial.suggest_categorical(feature, [True, False])\n",
    "    # ]\n",
    "\n",
    "    SELECTED_FEATURES = BEST_FEATURES\n",
    "    \n",
    "    rmse_scores = []\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Hyperparameter Search Space for XGBoost\n",
    "    # --------------------------------------------------\n",
    "    # Sample early_stopping_rounds separately so it can be passed to fit.\n",
    "    params = {\n",
    "        'base_score': trial.suggest_float('base_score', 0.0, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.5, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "        'max_delta_step': trial.suggest_int('max_delta_step', 0, 10),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 10, 250)\n",
    "    }\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Rolling Forecast Loop with Early Stopping\n",
    "    # --------------------------------------------------\n",
    "    # Loop over forecast windows (starting at index 24 to ensure an initial training period).\n",
    "    for X_train_df, X_predict_df, X_eval_df, y_actual in tqdm(windowed_sets, desc=f\"{worker_name} - {progress}\"):\n",
    "        model = xgb.XGBRegressor(\n",
    "            **params,\n",
    "            objective='reg:squarederror',\n",
    "            eval_metric='rmse',\n",
    "            random_state=42,\n",
    "            n_jobs=2\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_df[SELECTED_FEATURES], X_train_df[\"Price\"], eval_set=[(X_eval_df[SELECTED_FEATURES], X_eval_df[\"Price\"])], verbose=False\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_predict_df[SELECTED_FEATURES])\n",
    "        rmse = mean_squared_error(y_actual, preds)  ** 0.5\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    if len(rmse_scores) == 0:\n",
    "        return float('inf')\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    return avg_rmse\n",
    "\n",
    "def worker_process(study_name):\n",
    "    \"\"\"\n",
    "    Worker function that fetches trials from the database and optimizes them.\n",
    "    \"\"\"\n",
    "    storage = RDBStorage(DB_URL)  # Remove heartbeat_interval\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage, direction=\"minimize\", load_if_exists=True)\n",
    "    run = 1\n",
    "    while True:\n",
    "        try:\n",
    "            trial = study.ask()\n",
    "            if trial is None:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Database error: {e}\")\n",
    "            break\n",
    "        progress = f\"Run {run} of {N_TRIALS_TOTAL // NUM_WORKERS}\"\n",
    "        value = objective(trial, multiprocessing.current_process().name, progress)\n",
    "        study.tell(trial, value)\n",
    "        run+=1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study_name = \"XGB_hyperopt_params\"\n",
    "    study = optuna.create_study(study_name=study_name, storage=DB_URL, direction=\"minimize\", load_if_exists=True)\n",
    "\n",
    "    processes = []\n",
    "    for _ in range(NUM_WORKERS):\n",
    "        p = multiprocessing.Process(target=worker_process, args=(study_name,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best RMSE: {best_trial.value}\")\n",
    "    print(\"Best hyperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_FEATURES = [\n",
    "\"hour\",\n",
    "\"ma_11_days\",\n",
    "\"ma_12_days\",\n",
    "\"ma_12_days_pumped_storage_generation\",\n",
    "\"ma_13_days_pumped_storage_generation\",\n",
    "\"ma_1_days\",\n",
    "\"ma_2_days\",\n",
    "\"ma_2_days_pumped_storage_generation\",\n",
    "\"ma_3_days\",\n",
    "\"ma_4_days_pumped_storage_generation\",\n",
    "\"ma_5_days\",\n",
    "\"ma_5_days_pumped_storage_generation\",\n",
    "\"ma_6_days\",\n",
    "\"ma_6_days_pumped_storage_generation\",\n",
    "\"ma_8_days\",\n",
    "\"ma_8_days_pumped_storage_generation\",\n",
    "\"precipitation\",\n",
    "\"Solar\",\n",
    "\"temperature_2m\",\n",
    "\"Wind offshore\"    ,                    \n",
    "\"Wind onshore\"   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.stdout = open(\"output.log\", \"w\")  # Redirects print output to a file\n",
    "sys.stderr = sys.stdout  # Redirect errors as well\n",
    "\n",
    "import os\n",
    "os.environ[\"TMPDIR\"] = \"/home/user/tmp\"\n",
    "\n",
    "\n",
    "print(\"All outputs will be saved to output.log\")\n",
    "\n",
    "# =============================================================================\n",
    "# Precompute the Train/Test and Forecast Windows Outside the Objective\n",
    "# =============================================================================\n",
    "windowed_sets = []\n",
    "\n",
    "# Get and split datasets\n",
    "merged_df, _ = get_datasets()\n",
    "train, eval, test, benchmark, _, _, _ = split(merged_df)\n",
    "\n",
    "# Combine all available training data\n",
    "training_set = pd.concat([train, eval, test])[COLUMNS]\n",
    "benchmarking_set = benchmark[COLUMNS]\n",
    "\n",
    "# Iterate through forecast windows for rolling prediction\n",
    "for window_start in tqdm(range(WINDOW_SIZE, len(benchmarking_set) - (WINDOW_SIZE * 15), WINDOW_SIZE), desc=\"Preparing windowed datasets\"):\n",
    "    y_actual = benchmarking_set.iloc[window_start : window_start + WINDOW_SIZE][\"Price\"]\n",
    "    dataset_extended = pd.concat((training_set, benchmarking_set.iloc[:window_start]))\n",
    "    next_day = dataset_extended.index[-1] + pd.DateOffset(hours=1)\n",
    "\n",
    "    if next_day != y_actual.index[0]:\n",
    "        print(f\"\\nSkipping prediction for {next_day} due to missing entries.\\n\")\n",
    "        continue\n",
    "\n",
    "    dataset_extended_ps = extend_by_predictions_and_samples(dataset_extended, dataset_extended.index[-1])\n",
    "    dataset_extended_features = create_features(dataset_extended_ps)\n",
    "    \n",
    "    X_train_df = dataset_extended_features.iloc[:-WINDOW_SIZE]\n",
    "    X_predict_df = dataset_extended_features.reindex(y_actual.index)\n",
    "    \n",
    "    windowed_sets.append((X_train_df, X_predict_df, y_actual))\n",
    "\n",
    "DB_URL = \"postgresql://optuna_user:postgres@localhost/optuna_db\"\n",
    "NUM_WORKERS = 40\n",
    "N_TRIALS_TOTAL = 80\n",
    "\n",
    "def objective(trial, worker_name, progress):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    # SELECTED_FEATURES = [\n",
    "    #     feature for feature in CANDIDATE_FEATURES if trial.suggest_categorical(feature, [True, False])\n",
    "    # ]\n",
    "\n",
    "    SELECTED_FEATURES = BEST_FEATURES\n",
    "\n",
    "    params = {\n",
    "        \"changepoint_prior_scale\": trial.suggest_float(\"changepoint_prior_scale\", 0.001, 0.5, log=True),  # Trend flexibility\n",
    "        \"changepoint_range\": trial.suggest_float(\"changepoint_range\", 0.8, 0.95),  # % of history for changepoints\n",
    "        \"seasonality_mode\": trial.suggest_categorical(\"seasonality_mode\", [\"additive\", \"multiplicative\"]),\n",
    "        \"seasonality_prior_scale\": trial.suggest_float(\"seasonality_prior_scale\", 0.01, 10, log=True),  # Seasonality strength\n",
    "        \"yearly_seasonality\": trial.suggest_int(\"yearly_seasonality\", 5, 20),  # Fourier order for yearly seasonality\n",
    "        \"weekly_seasonality\": trial.suggest_int(\"weekly_seasonality\", 5, 20),  # Fourier order for weekly seasonality\n",
    "        \"daily_seasonality\": trial.suggest_int(\"daily_seasonality\", 5, 20),  # Fourier order for daily seasonality\n",
    "        \"holidays_prior_scale\": trial.suggest_float(\"holidays_prior_scale\", 0.01, 10, log=True),  # Holiday effects regularization\n",
    "        \"n_changepoints\": trial.suggest_int(\"n_changepoints\", 10, 50),  # Number of changepoints\n",
    "        \"interval_width\": trial.suggest_float(\"interval_width\", 0.7, 0.95),  # Prediction interval width\n",
    "    }\n",
    "\n",
    "    rmse_scores = []\n",
    "    for i, (X_train_df, X_predict_df, y_actual) in enumerate(windowed_sets):\n",
    "        tqdm.write(f\"{worker_name} processing window {i+1}/{len(windowed_sets)} - {progress}\")\n",
    "        X_train_prophet = (\n",
    "            X_train_df[[\"Price\"] + SELECTED_FEATURES]\n",
    "            .rename(columns={\"Price\": \"y\"})\n",
    "            .reset_index()\n",
    "            .rename(columns={\"index\": \"ds\"})\n",
    "            .dropna()\n",
    "        )\n",
    "        prophet_X_predict = X_predict_df[SELECTED_FEATURES].reset_index().rename(columns={\"index\": \"ds\"})\n",
    "\n",
    "        prophet_model = init_prophet_model(SELECTED_FEATURES, params=params)\n",
    "        prophet_model.fit(X_train_prophet)\n",
    "        prophet_forecast = prophet_model.predict(prophet_X_predict)[\"yhat\"]\n",
    "        rmse = mean_squared_error(y_actual, prophet_forecast) ** 0.5\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    return float('inf') if not rmse_scores else np.mean(rmse_scores)\n",
    "\n",
    "def worker_process(study_name):\n",
    "    \"\"\"\n",
    "    Worker function that fetches trials from the database and optimizes them.\n",
    "    \"\"\"\n",
    "    storage = RDBStorage(DB_URL)  # Remove heartbeat_interval\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage, direction=\"minimize\", load_if_exists=True)\n",
    "    run = 1\n",
    "    while True:\n",
    "        try:\n",
    "            trial = study.ask()\n",
    "            if trial is None:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Database error: {e}\")\n",
    "            break\n",
    "        progress = f\"Run {run} of {N_TRIALS_TOTAL // NUM_WORKERS}\"\n",
    "        value = objective(trial, multiprocessing.current_process().name, progress)\n",
    "        study.tell(trial, value)\n",
    "        run+=1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study_name = \"prophet_hyperopt_params\"\n",
    "    study = optuna.create_study(study_name=study_name, storage=DB_URL, direction=\"minimize\", load_if_exists=True)\n",
    "\n",
    "    processes = []\n",
    "    for _ in range(NUM_WORKERS):\n",
    "        p = multiprocessing.Process(target=worker_process, args=(study_name,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best RMSE: {best_trial.value}\")\n",
    "    print(\"Best hyperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
